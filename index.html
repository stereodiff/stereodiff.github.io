<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="StereoDiff: Stereo-Diffusion Synergy for Video Depth Estimation">
  <meta name="keywords" content="Video Depth Estimation, Stereo Matching, Video Diffusion Models">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>StereoDiff</title>

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-1FWSVCGZTG"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-1FWSVCGZTG');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./css/bulma.min.css">
  <link rel="stylesheet" href="./css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./css/bulma-slider.min.css">
  <link rel="stylesheet" href="./css/twentytwenty.css">
  <link rel="stylesheet" href="./css/index.css">
  <link rel="icon" href="./images/icon_circle.png">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

  <script src="./js/jquery-3.2.1.min.js"></script>
  <script src="./js/jquery.event.move.js"></script>
  <script src="./js/jquery.twentytwenty.js"></script>
  <script src="./js/bulma-carousel.min.js"></script>
  <script src="./js/bulma-slider.min.js"></script>
  <script src="./js/fontawesome.all.min.js"></script>

  <!--MathJax-->
  <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      },
      svg: {
        fontCache: 'global'
      }
    };
  </script>
  <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">StereoDiff: Stereo-Diffusion Synergy for Video Depth Estimation</h1>
<!--           <h3 class="title has-text-centered">arXiv 2025</h3> -->
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://haodong-li.com/" target="_blank" rel="noopener noreferrer">
                Haodong Li<sup>1,2</sup></a>,
            </span>
            <span class="author-block">
                <a href="https://cwchenwang.github.io/" target="_blank" rel="noopener noreferrer">
                Chen Wang<sup>1</sup></a>,
            </span>
            <span class="author-block">
                <a href="https://www.cis.upenn.edu/~leijh/" target="_blank" rel="noopener noreferrer">
                Jiahui Lei<sup>1</sup></a>,
            </span>
            <span class="author-block">
                <a href="https://www.cis.upenn.edu/~kostas/" target="_blank" rel="noopener noreferrer">
                Kostas Daniilidis<sup>1</sup></a>,
            </span>
            <span class="author-block">
              <a href="https://lingjie0206.github.io/" target="_blank" rel="noopener noreferrer">
                Lingjie Liu<sup>1&#9993;</sup></a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Pennsylvania</span>
            <span class="author-block"><sup>2</sup>HKUST(Guangzhou)</span>
            <br>
            <span class="author-block">
                <sup>&#9993;</sup>Corresponding author.
            </span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://arxiv.org/abs/2506.20756" target="_blank" rel="noopener noreferrer"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv" style="font-size:23px"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href="./paper.pdf" target="_blank" rel="noopener noreferrer"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fa fa-file-pdf" style="font-size:23px"></i>
                  </span>
                  <span>PDF</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://drive.google.com/file/d/1icXyNUaRdpLxeSyB4UkMtDT4JrkVh1O-/view?usp=drive_link" target="_blank" rel="noopener noreferrer"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-file-video" style="font-size:23px"></i>
                  </span>
                  <span>Video Results (158MB)</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="" target="_blank" rel="noopener noreferrer"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github" style="font-size:23px"></i>
                  </span>
                  <span>
                    Code (Coming Soon)
                  </span>
                </a>
              </span>
              <!-- Hugging Face Space (LCM). -->
              <!-- <span class="link-block">
                <a href="https://huggingface.co/spaces/haodongli/Lotus_Depth" target="_blank" rel="noopener noreferrer"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon" style="font-size:23px">
                      &#129303;
                  </span>
                  <span>Huggingface Demo</span>
                </a>
              </span> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body" text="center">
      <p style="text-align: center;">

        <video width="100%" controls autoplay loop muted>
            <source src="./images/teaser_compressed.mp4" type="video/mp4">
            <source src="./images/teaser_compressed.ogg" type="video/ogg">
            Your browser does not support HTML video. Please download the "Video Results" linked above.
        </video>

      </p>
      <div class="content has-text-justified">
        <p>
          <span class="methodname" style="font-weight: bold;">StereoDiff</span> excels in delivering remarkable global and local consistency for video depth estimation.<br>
        </p><p>
          In terms of global consistency, <span class="methodname" style="font-weight: bold;">StereoDiff</span> achieves highly accurate and stable depth maps on static backgrounds across consecutive windows, leveraging stereo matching to prevent the abrupt depth shifts often seen in DepthCrafter, where depth values on static backgrounds can vary significantly between adjacent windows.
        </p><p>
          For local consistency, <span class="methodname" style="font-weight: bold;">StereoDiff</span> yields much smoother, flicker-free depth values across consecutive frames, especially in dynamic regions. In contrast, MonST3R suffers from frequent, pronounced flickering and jitters in these areas.
        </p>
      </div>
    </div>
  </div>
</section>


<section class="section hero is-light">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
        <p>
            Recent video depth estimation methods achieve great performance by following the paradigm of image depth estimation, <i>i.e.</i>, typically fine-tuning pre-trained video diffusion models with massive data.
            However, we argue that video depth estimation is not a naive extension of image depth estimation.
            The temporal consistency requirements for dynamic and static regions in videos are fundamentally different.
            Consistent video depth in static regions, typically backgrounds, can be more effectively achieved via stereo matching across all frames, which provides much stronger global 3D cues.
            While the consistency for dynamic regions still should be learned from large-scale video depth data to ensure smooth transitions, due to the violation of triangulation constraints.
        </p><p>
            Based on these insights, we introduce <span class="methodname" style="font-weight: bold;">StereoDiff</span>, a two-stage video depth estimator that synergizes stereo matching for mainly the static areas with video depth diffusion for maintaining consistent depth transitions in dynamic areas.
            We mathematically demonstrate how stereo matching and video depth diffusion offer complementary strengths through frequency domain analysis, highlighting the effectiveness of their synergy in capturing the advantages of both.
        </p><p>
            Experimental results on zero-shot, real-world, dynamic video depth benchmarks, both indoor and outdoor, demonstrate <span class="methodname" style="font-weight: bold;">StereoDiff</span>'s SoTA performance, showcasing its superior consistency and accuracy in video depth estimation.
        </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Method. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Methodology</h2>
        <div class="content has-text-justified">

        <p>
            <strong>Pipeline of <span class="methodname" style="font-weight: bold;">StereoDiff</span>.</strong> &#9312; All video frames are paired for stereo matching in the first stage, primarily focusing on static backgrounds, in order to achieve a strong global consistency that provided by global 3D constraints. &#9313; Using the stereo matching-based video depth from the first stage, the second stage of <span class="methodname" style="font-weight: bold;">StereoDiff</span> applies a video depth diffusion for significantly improving the local consistency without sacrificing its original global consistency, resulting in video depth estimations with both strong global consistency and smooth local consistency.
        </p>
          
          <img id="method_train" width="100%" src="./images/pipe.jpg" alt="Marigold training scheme"/>

        </div>
          <h2 class="title is-3">Experiments</h2>
          <div class="content has-text-justified">

          <p>
            <strong>Quantitative comparison of <span class="methodname" style="font-weight: bold;">StereoDiff</span> with SoTA methods on zero-shot video depth benchmarks.</strong>
            The five sections from top to bottom represent: image depth estimators, stereo matching-based estimators, video depth diffusion models,
            <span class="methodname" style="font-weight: bold;">StereoDiff</span> using other stereo matching methods,
            and <span class="methodname" style="font-weight: bold;">StereoDiff</span>.
            To make sure a comprehensive evaluation, we used four datasets: Bonn, KITTI, ScanNetV2, and Sintel.
            We report the mean metrics of <span class="methodname" style="font-weight: bold;">StereoDiff</span> across 10 independent runs.
            MonST3R<sub><strong>OPT</strong></sub> (<sub><strong>OPT</strong></sub>: with optimization) can not be evaluated on long video depth benchmarks (<i>i.e.</i>, Bonn and ScanNetV2) due to computational constraints.
            Best results are <strong>bolded</strong> and the second best are <u>underlined</u>.
          </p>

          <img id="comparison" width="100%" src="./images/exp_depth.jpg" alt="Comparison with other methods"/>

          <p><strong>
            No temporal consistency metrics?
          </strong></p><p>
            The metrics above are not in per-frame manner.
            All frames in a predicted video depth use same scale and shift factors for affine-invariant evaluation.
            Temporal inconsistencies will lead to worse metrics. Testing MonST3R on Bonn with per-frame scale and shift yields an AbsRel of 0.0341, much better than the reported 0.0818.
          </p>
        </div>
      </div>
    </div>
    <!--/ Method. -->
  </div>
</section>


<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre class="selectable"><code>@article{he2024lotus,
    title={Lotus: Diffusion-based Visual Foundation Model for High-quality Dense Prediction},
    author={He, Jing and Li, Haodong and Yin, Wei and Liang, Yixun and Li, Leheng and Zhou, Kaiqiang and Liu, Hongbo and Liu, Bingbing and Chen, Ying-Cong},
    journal={arXiv preprint arXiv:2409.18124},
    year={2024}
}
</code></pre>
  </div>
</section> -->

<footer class="footer pt-4 pb-0">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            Website template based on
            <a href="https://marigoldmonodepth.github.io/">
            Marigold
            </a>
            and licensed under
            <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">
            CC-BY-SA-4.0
            </a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
